{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lilith** is a deep learning library in Julia with focus on **high performance** and **interoperability with existing DL frameworks**. Its main features include:\n",
    "\n",
    " * _tracing autograd engine_ - models are just structs, transformations are just functioins\n",
    " * _optimizing code generator_ based on hackable computational graph\n",
    " * _GPU support_\n",
    " * _layer API similar to PyTorch's_ to ease translation of existing Python code to Julia\n",
    " * high _backward compatibility_ to allow accumulation of models\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick example of Lilith model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Lilith\n",
    "\n",
    "\n",
    "mutable struct Net\n",
    "    conv1::Conv2d\n",
    "    conv2::Conv2d\n",
    "    fc1::Linear\n",
    "    fc2::Linear\n",
    "end\n",
    "\n",
    "\n",
    "Net() = Net(\n",
    "    Conv2d(1, 20, 5),\n",
    "    Conv2d(20, 50, 5),\n",
    "    Linear(4 * 4 * 50, 500),\n",
    "    Linear(500, 10)\n",
    ")\n",
    "\n",
    "\n",
    "function (m::Net)(x::AbstractArray)\n",
    "    x = maxpool2d(relu.(m.conv1(x)), (2, 2))\n",
    "    x = maxpool2d(relu.(m.conv2(x)), (2, 2))\n",
    "    x = reshape(x, 4*4*50, :)\n",
    "    x = relu.(m.fc1(x))\n",
    "    x = logsoftmax(m.fc2(x))\n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training (you may see a few warnings from underlying packages, but they shouldn't break anything):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1: avg_cost=0.0818943272211722, elapsed=12.219861569\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 2: avg_cost=0.08067442104220389, elapsed=11.577970364\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 3: avg_cost=0.078615898798619, elapsed=11.786745248\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 4: avg_cost=0.07356383970805576, elapsed=11.84160564\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 5: avg_cost=0.05924170171575886, elapsed=11.949758801\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 6: avg_cost=0.03640910144895315, elapsed=11.874725977\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 7: avg_cost=0.02330157606463347, elapsed=11.598434645\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 8: avg_cost=0.018194284556167464, elapsed=11.583370803\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 9: avg_cost=0.015693947872413055, elapsed=11.591046153\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n",
      "┌ Info: Epoch 10: avg_cost=0.014169146639427968, elapsed=11.557459894\n",
      "└ @ Lilith /home/slipslop/work/Lilith/src/fit.jl:25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.652222 seconds (42.22 M allocations: 8.994 GiB, 2.04% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(Conv2d(5x5, 1=>20), Conv2d(5x5, 20=>50), Linear(800=>500), Linear(500=>10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MLDatasets    # run `] add MLDatasets` to install this package\n",
    "\n",
    "function get_mnist_data(train::Bool; device=CPU())\n",
    "    X, Y = train ? MNIST.traindata() : MNIST.testdata()\n",
    "    X = convert(Array{Float64}, reshape(X, 28, 28, 1, :)) |> device\n",
    "    # replace class label like \"0\" with its position like \"1\"\n",
    "    Y = Y .+ 1 |> device\n",
    "    return X, Y\n",
    "end\n",
    "\n",
    "# choose device: if CUDA is available on the system, GPU() will be used, otherwise - CPU()\n",
    "device = best_available_device()\n",
    "\n",
    "# instantiate the model\n",
    "m = Net() |> device\n",
    "# load training data\n",
    "X_trn, Y_trn = get_mnist_data(true);\n",
    "# set loss function and optimizer, then fit the model\n",
    "loss_fn = NLLLoss()\n",
    "opt = Adam(lr=1e-2)\n",
    "@time fit!(m, X_trn, Y_trn, loss_fn; n_epochs=10, opt=opt, batch_size=100, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: 0.8959\n",
      "└ @ Main In[9]:7\n"
     ]
    }
   ],
   "source": [
    "import Lilith: accuracy\n",
    "\n",
    "# load test data\n",
    "X_tst, Y_tst = get_mnist_data(false, device=device)\n",
    "# predict log probabilities and calculate accuracy\n",
    "Ŷ = m(X_tst)\n",
    "@info accuracy(Y_tst, Ŷ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
